{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e334946-88c6-4a53-b68b-bc6a7812f446",
   "metadata": {},
   "source": [
    "# Laboratory 9 instruction part 2 - MLflow\n",
    "\n",
    "In machine learning development, one of the most challenging aspects is maintaining reproducibility. This issue is particularly relevant to the experimental phase, when a lot of small, but influential code changes are constantly introduced.\n",
    "\n",
    "After extensive experimentation with different model architectures, hyperparameters, and preprocessing techniques, researchers often find themselves unable to recreate their best-performing models because critical configuration details were not properly recorded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5635a486-ad7f-4d1e-b77a-60bb611ead52",
   "metadata": {},
   "source": [
    "## MLflow\n",
    "\n",
    "[MLflow is an open-source platform](https://mlflow.org/) that addresses this challenge by providing systematic experiment tracking throughout the machine learning lifecycle. It automatically captures configurations, metrics, and artifacts from each model training run, transforming ad-hoc model development into a structured, reproducible process. In this notebook, we will learn how to use MLflow to properly track experiments for both traditional machine learning and deep learning workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e1cc47-687c-43df-994b-8898e0cf0d35",
   "metadata": {},
   "source": [
    "### Learning objectives\n",
    "\n",
    "1. **Implement automated experiment tracking** using MLflow autologging capabilities with scikit-learn, enabling automatic capture of model parameters and metrics without writing additional tracking code.\n",
    "\n",
    "2. **Configure manual logging strategies** for PyTorch experiments, implementing custom tracking for metrics, parameters, and artifacts throughout the training process.\n",
    "\n",
    "3. **Analyze and compare experimental results** using MLflow tracking UI and programmatic APIs to identify optimal model configurations and understand performance patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b60082-6c05-4281-bd04-b116f50fde0d",
   "metadata": {},
   "source": [
    "### Laboratory plan\n",
    "\n",
    "1. **MLflow tracking server** configuration and deployment for experiment management\n",
    "2. **Automatic logging mechanisms** for scikit-learn experiments\n",
    "3. **Manual logging implementation** for PyTorch deep learning workflows\n",
    "4. **Hyperparameter optimization exercise** - systematic hyperparameter exploration\n",
    "5. **Best practices** for experiment organization, versioning, and cross-team reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74a40d6-c3a1-4a0c-901d-37f623083a0f",
   "metadata": {},
   "source": [
    "## 1. MLflow Tracking server configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cf0383-726a-4078-96f4-a4079221ef34",
   "metadata": {},
   "source": [
    "[MLflow Tracking](https://mlflow.org/docs/latest/tracking/) is the main component of MLflow, responsible for capturing, storing, and presenting metrics, logs, and other tracking data. MLflow is based on a client-server architecture, where the central MLflow server can serve potentially whole teams of data scientists. You can also simply run it as a local server from the commandline, as we will now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b54de5-897b-42fb-a8c5-88f68e829920",
   "metadata": {},
   "source": [
    "1. Create a directory for MLflow artifacts storage:\n",
    "```bash\n",
    "mkdir mlflow-artifacts\n",
    "```\n",
    "\n",
    "2. Start the MLflow tracking server:\n",
    "```bash\n",
    "mlflow server \\\n",
    "  --backend-store-uri sqlite:///mlflow.db \\\n",
    "  --default-artifact-root ./mlflow-artifacts \\\n",
    "  --host 0.0.0.0 \\\n",
    "  --port 5000\n",
    "```\n",
    "Important: Keep this terminal window open. The MLflow server will continue running and be accessible at http://localhost:5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc86b089-02d6-4d15-aacf-3a7c59fe976c",
   "metadata": {},
   "source": [
    "To verify if the server runs properly, let's connect to git:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72ee89df-7d88-418b-b0ea-955314a8027a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MLflow at: http://localhost:5001\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5001\")\n",
    "print(f\"Connected to MLflow at: {mlflow.get_tracking_uri()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404081bf-fd43-4b10-adf4-dd50cdfdfddb",
   "metadata": {},
   "source": [
    "Setup complete! You now have the MLflow server running as a separate process, and `mlflow` library in this Jupyter Notebook is connected to it. Just note that we had to use the proper host and port - if you want to connect to a remote server, modify the tracking URI appropriately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42e3dde-f410-4550-be8d-38b68a54c380",
   "metadata": {},
   "source": [
    "## 2. Automatic logging with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5eba059-863c-4d0c-b560-e3b988904a92",
   "metadata": {},
   "source": [
    "### 2.1 Dataset preparation\n",
    "\n",
    "In this section, we'll use the Ames Housing dataset to demonstrate MLflow's autologging capabilities with scikit-learn. Since we have already prepared the 2006-2008 data using DVC, we can use our preprocessed dataset here. As we have temporal data, the best way to evaluate our model is time (chronological) split, where the newest data is used for testing. We will assume that we have the data for years 2006 and 2007, and evaluate using data from 2008."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c9238db-6356-4efd-87c4-0c7fab9ba43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from feature_engine.encoding import RareLabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0bd3c46-9319-41e2-8725-4d84a8e88d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"data/ames_data_2006_2008.parquet\")\n",
    "\n",
    "df = df.sort_values(by=[\"YrSold\"])\n",
    "\n",
    "df_train = df[df[\"YrSold\"] < 2008]\n",
    "df_test = df[df[\"YrSold\"] == 2008]\n",
    "\n",
    "y_train = df_train.pop(\"SalePrice\")\n",
    "y_test = df_test.pop(\"SalePrice\")\n",
    "\n",
    "categorical_features = df_train.select_dtypes(include=\"object\").columns\n",
    "numerical_features = df_train.select_dtypes(exclude=\"object\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5919ec29-187c-4e6d-85b9-19ea3ed31bf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "median_imputer = SimpleImputer(strategy=\"median\")\n",
    "min_max_scaler = MinMaxScaler()\n",
    "rare_encoder = RareLabelEncoder(tol=0.01, n_categories=0)\n",
    "one_hot_encoder = OneHotEncoder(\n",
    "    drop=\"first\", sparse_output=False, handle_unknown=\"ignore\"\n",
    ")\n",
    "\n",
    "num_pipeline = Pipeline(\n",
    "    [(\"median_imputer\", median_imputer), (\"min_max_scaler\", min_max_scaler)]\n",
    ")\n",
    "\n",
    "cat_pipeline = Pipeline(\n",
    "    [(\"rare_encoder\", rare_encoder), (\"one_hot_encoder\", one_hot_encoder)]\n",
    ")\n",
    "\n",
    "column_transformer = ColumnTransformer(\n",
    "    [\n",
    "        (\"num_pipeline\", num_pipeline, numerical_features),\n",
    "        (\"cat_pipeline\", cat_pipeline, categorical_features),\n",
    "    ],\n",
    "    verbose_feature_names_out=False,\n",
    ")\n",
    "column_transformer.fit(df_train)\n",
    "\n",
    "X_train = column_transformer.transform(df_train)\n",
    "X_test = column_transformer.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f32f3cf3-c57e-4747-a641-58cd5b3efc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 1312\n",
      "Test samples: 621\n",
      "Number of features: 181\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training samples: {X_train.shape[0]}\")\n",
    "print(f\"Test samples: {X_test.shape[0]}\")\n",
    "print(f\"Number of features: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b0c8a1-8c4b-4e7c-bc94-a17b66c35496",
   "metadata": {},
   "source": [
    "### 2.2 Training with MLflow autologging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e15737-282d-4b0a-9930-6bfdbf506aa0",
   "metadata": {},
   "source": [
    "Autologging is a powerful built-in capability of MLflow, enabling fully automated and near-zero code integration of MLflow with many popular frameworks. In particular, it works really well with scikit-learn, thanks to its highly unified API. Let's try this out - we will enable autologging, and then train a buch of different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07209ba8-d906-47ec-b95f-bc49ea002c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/07 13:43:06 WARNING mlflow.utils.autologging_utils: MLflow sklearn autologging is known to be compatible with 0.24.1 <= scikit-learn <= 1.6.1, but the installed version is 1.7.0. If you encounter errors during autologging, try upgrading / downgrading scikit-learn to a compatible version, or try upgrading MLflow.\n",
      "2025/06/07 13:43:07 INFO mlflow.tracking.fluent: Experiment with name 'ames-housing-autolog' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/Users/rafalrak/studia/mlops_lab06_dvc/mlflow-artifacts/1', creation_time=1749296587553, experiment_id='1', last_update_time=1749296587553, lifecycle_stage='active', name='ames-housing-autolog', tags={}>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.sklearn.autolog(\n",
    "    log_input_examples=True, log_model_signatures=True, log_models=False, silent=False\n",
    ")\n",
    "\n",
    "mlflow.set_experiment(\"ames-housing-autolog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fab8fe1e-28d4-473e-acfd-32ddefea106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "\n",
    "models = [\n",
    "    (\"Ridge Regression\", Ridge()),\n",
    "    (\"Decision Tree\", DecisionTreeRegressor(max_depth=10, random_state=42)),\n",
    "    (\"K-Nearest Neighbors\", KNeighborsRegressor(n_neighbors=10)),\n",
    "    (\"Random Forest\", RandomForestRegressor(n_estimators=100, random_state=42)),\n",
    "    (\"Gradient Boosting\", GradientBoostingRegressor(n_estimators=100, random_state=42)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c80ebf7f-af99-461a-b35f-e2d7e6676645",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "def fit_sklearn_models_with_cv(models, X_train, X_test, y_train, y_test):\n",
    "    results = {}\n",
    "\n",
    "    for model_name, model in models:\n",
    "        # start MLflow run - a unit grouping logs from different model runs\n",
    "        # everything within this context manager will get logged as a run\n",
    "        with mlflow.start_run(run_name=model_name):\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            rmse = root_mean_squared_error(y_test, y_pred)\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "            cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring=\"r2\")\n",
    "            cv_mean = cv_scores.mean()\n",
    "            cv_std = cv_scores.std()\n",
    "\n",
    "            # log additional custom metrics, in addition to autologging\n",
    "            mlflow.log_metric(\"cv_r2_mean\", cv_mean)\n",
    "            mlflow.log_metric(\"cv_r2_std\", cv_std)\n",
    "\n",
    "            results[model_name] = {\n",
    "                \"rmse\": rmse,\n",
    "                \"mae\": mae,\n",
    "                \"r2\": r2,\n",
    "                \"cv_r2_mean\": cv_mean,\n",
    "            }\n",
    "\n",
    "            print(f\"\\n{model_name}:\")\n",
    "            print(f\"  RMSE: {rmse:.2f}\")\n",
    "            print(f\"  MAE: {mae:.2f}\")\n",
    "            print(f\"  R^2: {r2:.3f}\")\n",
    "            print(f\"  CV R^2 (mean ± std): {cv_mean:.3f} ± {cv_std:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "808bb766-f598-4cbd-a46f-3bad82d84f4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/07 13:43:07 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:08 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:08 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:08 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:08 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:08 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:08 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:08 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:08 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:08 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:08 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:08 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:08 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ridge Regression:\n",
      "  RMSE: 23450.39\n",
      "  MAE: 16430.79\n",
      "  R^2: 0.904\n",
      "  CV R^2 (mean ± std): 0.895 ± 0.035\n",
      "🏃 View run Ridge Regression at: http://localhost:5001/#/experiments/1/runs/830dcd88e896459c87e0e58757dc22f2\n",
      "🧪 View experiment at: http://localhost:5001/#/experiments/1\n",
      "\n",
      "Decision Tree:\n",
      "  RMSE: 36860.51\n",
      "  MAE: 23270.66\n",
      "  R^2: 0.762\n",
      "  CV R^2 (mean ± std): 0.755 ± 0.057\n",
      "🏃 View run Decision Tree at: http://localhost:5001/#/experiments/1/runs/09886279375a40c7a74d136f68578900\n",
      "🧪 View experiment at: http://localhost:5001/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/07 13:43:08 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:08 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:08 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:08 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:08 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:08 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K-Nearest Neighbors:\n",
      "  RMSE: 38324.60\n",
      "  MAE: 26033.27\n",
      "  R^2: 0.743\n",
      "  CV R^2 (mean ± std): 0.691 ± 0.049\n",
      "🏃 View run K-Nearest Neighbors at: http://localhost:5001/#/experiments/1/runs/3483a00c72a94f8a99f0641ab51478ca\n",
      "🧪 View experiment at: http://localhost:5001/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/07 13:43:09 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:10 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:11 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:12 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:12 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:13 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest:\n",
      "  RMSE: 25814.13\n",
      "  MAE: 15606.16\n",
      "  R^2: 0.883\n",
      "  CV R^2 (mean ± std): 0.879 ± 0.049\n",
      "🏃 View run Random Forest at: http://localhost:5001/#/experiments/1/runs/13cdba0403d94863a3f8d757693801a4\n",
      "🧪 View experiment at: http://localhost:5001/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/07 13:43:14 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:14 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:14 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:15 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:15 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient Boosting:\n",
      "  RMSE: 21600.50\n",
      "  MAE: 13840.01\n",
      "  R^2: 0.918\n",
      "  CV R^2 (mean ± std): 0.904 ± 0.031\n",
      "🏃 View run Gradient Boosting at: http://localhost:5001/#/experiments/1/runs/509fe9f5b6e84c8281700aad4272f42b\n",
      "🧪 View experiment at: http://localhost:5001/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "fit_sklearn_models_with_cv(models, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdc3a2c-f5e8-4f96-935a-8975814b4306",
   "metadata": {},
   "source": [
    "Open the MLflow dashboard at http://localhost:5000/ and go to the Experiments tab. On the left, you have the experiment name, and when you select it, the list of all experiments will show up. Click through the interface and familiarize yourself with the most important elements:\n",
    "\n",
    "1. What columns can be selected\n",
    "2. Pick a particular run and check what values are logged automatically\n",
    "3. Select columns to compare a given metric between runs, e.g. MAE\n",
    "4. Sort algorithms by the selected metric to pick the best one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ffef97-b1be-4506-8720-c90e027c8172",
   "metadata": {},
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e97c74e-7cb4-4bfe-9f32-7421dc6c03e7",
   "metadata": {},
   "source": [
    "We have trained 5 different models. The results of all of them can now be compared in MLflow. Since we obtained quite satisfactory results, our imaginary client would like to be sure that we do our best and wants us to compare many more combinations.\n",
    "\n",
    "Your task is to run 5 more experiments with different parameters and models from scikit-learn. You can use any [supervised learning methods from scikit-learn](https://scikit-learn.org/stable/supervised_learning.html). Find some other models or parameters to tune our current models with and run the experiments again. Use the function `fit_sklearn_models_with_cv()` created above, or you can write your own if you want.\n",
    "\n",
    "Did you manage to beat the previous approaches?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef6261dd-3a22-4513-b524-2f40843919f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV, SGDRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn import svm\n",
    "\n",
    "models = models + [\n",
    "    (\"ElasticNet\", ElasticNetCV()),\n",
    "    (\"Support Vector Regression\", svm.SVR()),\n",
    "    (\"Stochastic Gradient Descent Regressor\", SGDRegressor()),\n",
    "    (\"Gaussian Process Regression\", GaussianProcessRegressor()),\n",
    "    (\"PLSRegression\", PLSRegression()),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bce4a78-8090-4814-adc4-ae80d33cb961",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/07 13:43:15 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:15 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:15 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:15 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:15 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:15 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:15 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:15 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:15 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:15 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ridge Regression:\n",
      "  RMSE: 23450.39\n",
      "  MAE: 16430.79\n",
      "  R^2: 0.904\n",
      "  CV R^2 (mean ± std): 0.895 ± 0.035\n",
      "🏃 View run Ridge Regression at: http://localhost:5001/#/experiments/1/runs/6a632db648054006a60b08996e8cc050\n",
      "🧪 View experiment at: http://localhost:5001/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/07 13:43:15 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:15 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree:\n",
      "  RMSE: 36860.51\n",
      "  MAE: 23270.66\n",
      "  R^2: 0.762\n",
      "  CV R^2 (mean ± std): 0.755 ± 0.057\n",
      "🏃 View run Decision Tree at: http://localhost:5001/#/experiments/1/runs/7a5888ac08db479f9d1af8b6970fbabf\n",
      "🧪 View experiment at: http://localhost:5001/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/07 13:43:15 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:16 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:16 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:16 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:16 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:16 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K-Nearest Neighbors:\n",
      "  RMSE: 38324.60\n",
      "  MAE: 26033.27\n",
      "  R^2: 0.743\n",
      "  CV R^2 (mean ± std): 0.691 ± 0.049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/07 13:43:16 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run K-Nearest Neighbors at: http://localhost:5001/#/experiments/1/runs/5460df54c3d647f3b9d57cd9a1108e8c\n",
      "🧪 View experiment at: http://localhost:5001/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/07 13:43:17 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:18 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:18 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:19 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:20 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:21 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest:\n",
      "  RMSE: 25814.13\n",
      "  MAE: 15606.16\n",
      "  R^2: 0.883\n",
      "  CV R^2 (mean ± std): 0.879 ± 0.049\n",
      "🏃 View run Random Forest at: http://localhost:5001/#/experiments/1/runs/3e6cc00f30734c4db33ff5ee4d9e6061\n",
      "🧪 View experiment at: http://localhost:5001/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/07 13:43:21 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:22 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:22 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:22 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:23 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:23 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:23 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:23 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:23 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:23 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient Boosting:\n",
      "  RMSE: 21600.50\n",
      "  MAE: 13840.01\n",
      "  R^2: 0.918\n",
      "  CV R^2 (mean ± std): 0.904 ± 0.031\n",
      "🏃 View run Gradient Boosting at: http://localhost:5001/#/experiments/1/runs/ba88fe08b22748ca80eafbf83e8171e6\n",
      "🧪 View experiment at: http://localhost:5001/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/07 13:43:23 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:23 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ElasticNet:\n",
      "  RMSE: 72699.47\n",
      "  MAE: 54750.09\n",
      "  R^2: 0.075\n",
      "  CV R^2 (mean ± std): 0.019 ± 0.079\n",
      "🏃 View run ElasticNet at: http://localhost:5001/#/experiments/1/runs/43918422ace14b0189eb0e538b7bc374\n",
      "🧪 View experiment at: http://localhost:5001/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/07 13:43:24 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:24 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:24 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:24 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:24 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:24 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:25 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:25 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:25 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Support Vector Regression:\n",
      "  RMSE: 77482.01\n",
      "  MAE: 54914.40\n",
      "  R^2: -0.051\n",
      "  CV R^2 (mean ± std): -0.103 ± 0.070\n",
      "🏃 View run Support Vector Regression at: http://localhost:5001/#/experiments/1/runs/c44121b5e01641139932571f247e9039\n",
      "🧪 View experiment at: http://localhost:5001/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/07 13:43:25 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:25 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:25 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stochastic Gradient Descent Regressor:\n",
      "  RMSE: 24109.50\n",
      "  MAE: 17277.60\n",
      "  R^2: 0.898\n",
      "  CV R^2 (mean ± std): 0.890 ± 0.031\n",
      "🏃 View run Stochastic Gradient Descent Regressor at: http://localhost:5001/#/experiments/1/runs/136093b5b0fc4b4e97d4681eb7fe4e36\n",
      "🧪 View experiment at: http://localhost:5001/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/07 13:43:25 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:25 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:25 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:25 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:26 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:26 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:26 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:26 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:26 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:26 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n",
      "2025/06/07 13:43:26 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gaussian Process Regression:\n",
      "  RMSE: 162799.40\n",
      "  MAE: 148233.18\n",
      "  R^2: -3.639\n",
      "  CV R^2 (mean ± std): -3.122 ± 0.888\n",
      "🏃 View run Gaussian Process Regression at: http://localhost:5001/#/experiments/1/runs/8a8ded7ce20e4e3d86219d4c0fbf70cd\n",
      "🧪 View experiment at: http://localhost:5001/#/experiments/1\n",
      "\n",
      "PLSRegression:\n",
      "  RMSE: 26520.31\n",
      "  MAE: 18893.55\n",
      "  R^2: 0.877\n",
      "  CV R^2 (mean ± std): 0.866 ± 0.039\n",
      "🏃 View run PLSRegression at: http://localhost:5001/#/experiments/1/runs/3b7c71ecaa1942c9bbd4b70437d6aa81\n",
      "🧪 View experiment at: http://localhost:5001/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "fit_sklearn_models_with_cv(models, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb882787-8a22-45a5-93ac-c232f467303a",
   "metadata": {},
   "source": [
    "## 3. Manual logging with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b51341-4f9b-437e-b17c-d882759cffea",
   "metadata": {},
   "source": [
    "In this section, we'll implement manual logging for PyTorch models. While scikit-learn has autologging, PyTorch requires manual tracking - giving us full control over what and when to log. MLflow supports autologging for [PyTorch Lightning](https://lightning.ai/docs/pytorch/stable/), but many people prefer or often need low-level control of pure PyTorch. Thus, we will focus on this approach, which also will teach us more about powerful MLflow capabilities.\n",
    "\n",
    "Note that we need to turn off scikit-learn autologging! Since we are using a Jupyter Notebook, MLflow uses the previously configured autologging unless explicitly turned off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b08b265d-b3b0-47d8-a207-7e0f6611de64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/07 13:43:26 INFO mlflow.tracking.fluent: Experiment with name 'pytorch-housing-manual' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/Users/rafalrak/studia/mlops_lab06_dvc/mlflow-artifacts/2', creation_time=1749296606425, experiment_id='2', last_update_time=1749296606425, lifecycle_stage='active', name='pytorch-housing-manual', tags={}>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# disable sklearn autologging!\n",
    "mlflow.sklearn.autolog(disable=True)\n",
    "\n",
    "mlflow.set_experiment(\"pytorch-housing-manual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b43a24-f469-4520-9634-8e77535d1f79",
   "metadata": {},
   "source": [
    "### 3.1 Targets transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a6a152-dc89-4c3e-92ab-d988324c5fc3",
   "metadata": {},
   "source": [
    "Before training the neural network, we will transform the training target, in order to stabilize the training. To see why, let's plot the house prices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d891bdee-750b-4c89-8153-4ea77dc1e720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train.plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb5e9b2-b596-4d43-9a70-a9ebd9228bcf",
   "metadata": {},
   "source": [
    "Training on such targets is possible, but very large target values easily risk overflow, particularly when a loss function like mean squared error is used. We will use the log-transform to transform this distribution, as it's near-exponential, so it should bring it closer to normal, and also greatly reduce the values range.\n",
    "\n",
    "Of course, we will need to transform the network predictions back again to evaluate them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2040911-8f01-4c83-9668-1b2340f03a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train_log = np.log1p(y_train)\n",
    "\n",
    "pd.Series(y_train_log).plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe63d74-b06f-4270-adad-d216bfbfa0dd",
   "metadata": {},
   "source": [
    "### 3.2 Define and train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed10560-7d86-44a2-9849-56abe78a8c04",
   "metadata": {},
   "source": [
    "Since we have tabular data, we will use a simple 2-layer multilayer perceptron (MLP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a115323-d4b5-4137-977d-8cc0579a5ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HousePriceNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=128, dropout_rate=0.2):\n",
    "        super(HousePriceNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cdb980-c4b6-462e-8fe2-27023ee97083",
   "metadata": {},
   "source": [
    "For training, we will check both the 5-fold CV performance, and the traditional train-test split. Cross-validation will give us an additional, robust performance estimation, as well as standard deviation, which is useful for comparing performances of different models. After all, if the difference between models would be within one standard deviation, it wouldn't really be meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76d6531a-3019-4f7e-94e5-238ee39af849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class PyTorchTrainer:\n",
    "    def __init__(self, model_class: type[nn.Module], config: dict):\n",
    "        self.model_class = model_class\n",
    "        self.config = config\n",
    "\n",
    "    def create_model(self, input_dim: int) -> nn.Module:\n",
    "        return self.model_class(\n",
    "            input_dim=input_dim,\n",
    "            hidden_dim=self.config[\"hidden_units\"],\n",
    "            dropout_rate=self.config[\"dropout\"],\n",
    "        )\n",
    "\n",
    "    def create_data_loader(\n",
    "        self, X: torch.Tensor, y: torch.Tensor, shuffle: bool = True\n",
    "    ) -> DataLoader:\n",
    "        dataset = TensorDataset(X, y)\n",
    "        return DataLoader(\n",
    "            dataset, batch_size=self.config[\"batch_size\"], shuffle=shuffle\n",
    "        )\n",
    "\n",
    "    def train_epoch(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        train_loader: DataLoader,\n",
    "        criterion: nn.Module,\n",
    "        optimizer: optim.Optimizer,\n",
    "    ) -> float:\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        batch_count = 0\n",
    "\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            batch_count += 1\n",
    "\n",
    "        return epoch_loss / batch_count\n",
    "\n",
    "    def train_model(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        train_loader: DataLoader,\n",
    "        epochs: int,\n",
    "        metric_prefix: str = \"\",\n",
    "    ) -> None:\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=self.config[\"learning_rate\"])\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            avg_mse = self.train_epoch(model, train_loader, criterion, optimizer)\n",
    "\n",
    "            if epoch % self.config[\"log_interval\"] == 0:\n",
    "                metric_name = (\n",
    "                    f\"{metric_prefix}train_mse\" if metric_prefix else \"train_mse\"\n",
    "                )\n",
    "                # manually log metric value, with a given name and step value\n",
    "                mlflow.log_metric(metric_name, avg_mse, step=epoch)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def evaluate_model(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        X: torch.Tensor,\n",
    "        y_test: torch.Tensor,\n",
    "        log_prefix: str = \"\",\n",
    "    ) -> dict[str, float]:\n",
    "        model.eval()\n",
    "\n",
    "        y_pred_norm = model(X)\n",
    "\n",
    "        # revert the logarithm with exponent\n",
    "        y_pred = np.expm1(y_pred_norm.numpy())\n",
    "        y_test = y_test.numpy()\n",
    "\n",
    "        rmse = root_mean_squared_error(y_test.ravel(), y_pred.ravel())\n",
    "        mae = mean_absolute_error(y_test.ravel(), y_pred.ravel())\n",
    "        r2 = r2_score(y_test.ravel(), y_pred.ravel())\n",
    "\n",
    "        if log_prefix:\n",
    "            # manually log metrics that we want\n",
    "            mlflow.log_metric(f\"{log_prefix}_rmse\", rmse)\n",
    "            mlflow.log_metric(f\"{log_prefix}_mae\", mae)\n",
    "            mlflow.log_metric(f\"{log_prefix}_r2\", r2)\n",
    "\n",
    "        return {\"rmse\": rmse, \"mae\": mae, \"r2\": r2}\n",
    "\n",
    "    def run_cross_validation(\n",
    "        self, X_train: torch.Tensor, y_train: torch.Tensor, n_splits: int = 5\n",
    "    ) -> tuple[float, float, list[float]]:\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "        cv_scores = []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
    "            print(f\"\\nTraining Fold {fold + 1}/{n_splits}...\")\n",
    "\n",
    "            X_fold_train = X_train[train_idx]\n",
    "            y_fold_train = y_train[train_idx]\n",
    "            X_fold_val = X_train[val_idx]\n",
    "            y_fold_val = y_train[val_idx]\n",
    "\n",
    "            fold_model = self.create_model(X_train.shape[1])\n",
    "            fold_loader = self.create_data_loader(X_fold_train, y_fold_train)\n",
    "\n",
    "            self.train_model(\n",
    "                fold_model,\n",
    "                fold_loader,\n",
    "                self.config[\"epochs\"],\n",
    "                metric_prefix=f\"fold_{fold + 1}_\",\n",
    "            )\n",
    "\n",
    "            # transform validation data with exponent back to original unit\n",
    "            y_fold_val = np.expm1(y_fold_val)\n",
    "\n",
    "            val_metrics = self.evaluate_model(\n",
    "                fold_model, X_fold_val, y_fold_val, log_prefix=f\"fold_{fold + 1}_val\"\n",
    "            )\n",
    "\n",
    "            cv_scores.append(val_metrics[\"r2\"])\n",
    "            print(\n",
    "                f\"  Fold {fold + 1} \"\n",
    "                f\"Validation - RMSE: {val_metrics['rmse']:.2f}, \"\n",
    "                f\"MAE: {val_metrics['mae']:.2f} \"\n",
    "                f\"R^2: {val_metrics['r2']:.3f}\"\n",
    "            )\n",
    "\n",
    "        return np.mean(cv_scores), np.std(cv_scores), cv_scores\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        X_train: pd.DataFrame | np.ndarray,\n",
    "        y_train: pd.Series | np.ndarray,\n",
    "        X_test: pd.DataFrame | np.ndarray,\n",
    "        y_test: pd.Series | np.ndarray,\n",
    "    ) -> dict:\n",
    "        X_train, X_test, y_train, y_test = self._prepare_tensors(\n",
    "            X_train, X_test, y_train, y_test\n",
    "        )\n",
    "\n",
    "        with mlflow.start_run(run_name=self.config[\"name\"]):\n",
    "            mlflow.log_params(self.config)\n",
    "\n",
    "            print(f\"Starting 5-fold cross-validation for {self.config['name']}...\")\n",
    "            cv_mean, cv_std, cv_scores = self.run_cross_validation(X_train, y_train)\n",
    "\n",
    "            mlflow.log_metric(\"cv_r2_mean\", cv_mean)\n",
    "            mlflow.log_metric(\"cv_r2_std\", cv_std)\n",
    "\n",
    "            print(\n",
    "                f\"\\nCross-validation complete. Mean R^2: {cv_mean:.3f} (+/- {cv_std:.3f})\"\n",
    "            )\n",
    "            print(\"\\nTraining final model on all training data...\")\n",
    "\n",
    "            final_model = self.create_model(X_train.shape[1])\n",
    "            final_loader = self.create_data_loader(X_train, y_train)\n",
    "\n",
    "            self.train_model(\n",
    "                final_model,\n",
    "                final_loader,\n",
    "                self.config[\"epochs\"],\n",
    "                metric_prefix=\"final_model_\",\n",
    "            )\n",
    "\n",
    "            print(\"\\nEvaluating on test set...\")\n",
    "            test_metrics = self.evaluate_model(final_model, X_test, y_test)\n",
    "\n",
    "            mlflow.log_metric(\"test_rmse\", test_metrics[\"rmse\"])\n",
    "            mlflow.log_metric(\"test_mae\", test_metrics[\"mae\"])\n",
    "            mlflow.log_metric(\"test_r2\", test_metrics[\"r2\"])\n",
    "\n",
    "            self._print_results(test_metrics, cv_mean, cv_std)\n",
    "\n",
    "            return {\n",
    "                \"rmse\": test_metrics[\"rmse\"],\n",
    "                \"mae\": test_metrics[\"mae\"],\n",
    "                \"r2\": test_metrics[\"r2\"],\n",
    "                \"cv_r2_mean\": cv_mean,\n",
    "                \"cv_r2_std\": cv_std,\n",
    "                \"cv_scores\": cv_scores,\n",
    "            }\n",
    "\n",
    "    def _prepare_tensors(self, X_train, X_test, y_train, y_test) -> tuple:\n",
    "        y_train = np.array(y_train)\n",
    "        y_test = np.array(y_test)\n",
    "\n",
    "        X_train_tensor = torch.FloatTensor(X_train)\n",
    "        y_train_tensor = torch.FloatTensor(y_train.reshape(-1, 1))\n",
    "\n",
    "        X_test_tensor = torch.FloatTensor(X_test)\n",
    "        y_test_tensor = torch.FloatTensor(y_test.reshape(-1, 1))\n",
    "\n",
    "        print(f\"Training samples: {X_train_tensor.shape[0]}\")\n",
    "        print(f\"Input features: {X_train_tensor.shape[1]}\")\n",
    "\n",
    "        return X_train_tensor, X_test_tensor, y_train_tensor, y_test_tensor\n",
    "\n",
    "    def _print_results(\n",
    "        self, test_metrics: dict[str, float], cv_mean: float, cv_std: float\n",
    "    ) -> None:\n",
    "        print(f\"{'=' * 50}\\n\")\n",
    "        print(f\"  Mean R^2: {cv_mean:.3f} (+/- {cv_std:.3f})\")\n",
    "        print(\"\\nCross-Validation Performance:\")\n",
    "        print(f\"  R^2: {test_metrics['r2']:.3f}\")\n",
    "        print(f\"  RMSE: {test_metrics['rmse']:.2f}\")\n",
    "        print(f\"  MAE: {test_metrics['mae']:.2f}\")\n",
    "        print(\"Test Set Performance:\")\n",
    "        print(f\"{'=' * 50}\")\n",
    "        print(f\"FINAL RESULTS for {self.config['name']}:\")\n",
    "        print(f\"\\n{'=' * 50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2388014f-25b4-4662-a6bd-6c798f1334b3",
   "metadata": {},
   "source": [
    "Quite a bit of code there! So now let's train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "946bd5bf-6e49-49be-88a7-26eedcc6d8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_config = {\n",
    "    \"model_class\": HousePriceNet,\n",
    "    \"random_seed\": 42,\n",
    "    \"log_interval\": 5,\n",
    "    \"num_samples\": X_train.shape[0],\n",
    "    \"input_features\": X_train.shape[1],\n",
    "    \"k_folds\": 5,\n",
    "}\n",
    "\n",
    "config = {\n",
    "    \"name\": \"first_run\",\n",
    "    \"hidden_units\": 128,\n",
    "    \"dropout\": 0.1,\n",
    "    \"learning_rate\": 0.03,\n",
    "    \"epochs\": 150,\n",
    "    \"batch_size\": 32,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "223910e8-22e0-4b90-a2fe-00a64b4125c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 1312\n",
      "Input features: 181\n",
      "Starting 5-fold cross-validation for first_run...\n",
      "\n",
      "Training Fold 1/5...\n",
      "  Fold 1 Validation - RMSE: 25042.59, MAE: 17844.56 R^2: 0.913\n",
      "\n",
      "Training Fold 2/5...\n",
      "  Fold 2 Validation - RMSE: 28725.20, MAE: 19826.05 R^2: 0.865\n",
      "\n",
      "Training Fold 3/5...\n",
      "  Fold 3 Validation - RMSE: 23346.09, MAE: 16619.20 R^2: 0.919\n",
      "\n",
      "Training Fold 4/5...\n",
      "  Fold 4 Validation - RMSE: 41956.80, MAE: 30354.07 R^2: 0.692\n",
      "\n",
      "Training Fold 5/5...\n",
      "  Fold 5 Validation - RMSE: 25240.81, MAE: 17881.26 R^2: 0.890\n",
      "\n",
      "Cross-validation complete. Mean R^2: 0.856 (+/- 0.084)\n",
      "\n",
      "Training final model on all training data...\n",
      "\n",
      "Evaluating on test set...\n",
      "==================================================\n",
      "\n",
      "  Mean R^2: 0.856 (+/- 0.084)\n",
      "\n",
      "Cross-Validation Performance:\n",
      "  R^2: 0.865\n",
      "  RMSE: 27753.08\n",
      "  MAE: 19873.93\n",
      "Test Set Performance:\n",
      "==================================================\n",
      "FINAL RESULTS for first_run:\n",
      "\n",
      "==================================================\n",
      "🏃 View run first_run at: http://localhost:5001/#/experiments/2/runs/93dcb8878274404d8b8865c8f7f06312\n",
      "🧪 View experiment at: http://localhost:5001/#/experiments/2\n"
     ]
    }
   ],
   "source": [
    "training_config = base_config | config\n",
    "\n",
    "trainer = PyTorchTrainer(training_config[\"model_class\"], training_config)\n",
    "results = trainer.fit(X_train, y_train_log, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4aba34-309b-4a60-b9b8-81e313930c2e",
   "metadata": {},
   "source": [
    "Go to the MLflow dashboard and take a look at logged values. Focus particularly on the \"Model metrics\" tab, which for neural networks visualizes the progress of iterative training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e10dbd9-db33-4d01-8e8c-62b337790fb0",
   "metadata": {},
   "source": [
    "### 3.3 Hyperparameter optimization with MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f29c2b4-b06f-45d6-be97-faf6a12bf48e",
   "metadata": {},
   "source": [
    "Now, we will use MLflow logging and visualization capabilities to help us tune hyperparameters of neural networks. This is one of the major applications of experiment tracking frameworks. As neural networks have many hyperparameters, with complex interactions, and training them many times is very computationally intensive, we want to use human judgment, based on plots and metrics, to guide our choices in further experiments.\n",
    "\n",
    "A quick recap on main hyperparameters of MLPs:\n",
    "\n",
    "1. **Learning rate:**\n",
    "   - typically 1e-5 to 1e-1\n",
    "   - too high: loss explodes, model diverges\n",
    "   - too low: slow convergence, might get stuck\n",
    "   - sweet spot: fast convergence to good minimum\n",
    "\n",
    "3. **Model size** - number of hidden units here:\n",
    "   - typically 32 to 512\n",
    "   - too few: underfitting, can't capture patterns\n",
    "   - too many: overfitting, slow training, diminishing returns\n",
    "   - consider: more features need more capacity\n",
    "\n",
    "5. **Dropout rate:**\n",
    "   - typically 0.0 to 0.5\n",
    "   - 0.0: no regularization, risk overfitting\n",
    "   - too high: underfitting, loses important information\n",
    "   - purpose: prevents over-reliance on specific neurons\n",
    "\n",
    "7. **Batch size:**\n",
    "   - typically 16 to 128\n",
    "   - small: noisy gradients, often better generalization, slower\n",
    "   - large: stable gradients, faster training, needs more memory, may overfit\n",
    "   - trade-off: speed vs generalization\n",
    "\n",
    "9. **Number of epochs:**\n",
    "   - too few: underfitting\n",
    "   - too many: overfitting\n",
    "   - optimal: when validation loss stops improving\n",
    "   - watch validation loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd8408a-af15-495f-9317-ebef6ba12607",
   "metadata": {},
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068c8473-e559-411b-9fe7-af11bb6a90b5",
   "metadata": {},
   "source": [
    "Your task is to:\n",
    "1. Run 10 experiments by modifying the hyperparameter configuration. Try to improve model performance, which is currently overfitted.\n",
    "2. Analyze results in MLflow UI.\n",
    "3. Comment on what changes impacted the model performance the most, and what changes disrupted the training process.\n",
    "4. Compare the results of our first scikit-learn configuration with the first PyTorch experiments. Do you see any overfitting in the first PyTorch experiment? Explain what signs of overfitting can indicate this situation.\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "\n",
    "base_config = {\n",
    "    # or any other your own architecture :) we definitely recommend to experiment by yourselves\n",
    "    \"model_class\": HousePriceNet,\n",
    "    \"random_seed\": 42,\n",
    "    \"log_interval\": 5,\n",
    "    \"input_features\": X_train.shape[1],\n",
    "    \"num_samples\": X_train.shape[0],\n",
    "    \"target_normalized\": True,\n",
    "    \"k_folds\": 5,\n",
    "}\n",
    "\n",
    "configs = {\n",
    "     {\n",
    "        \"name\": \"first_run_or_other_your_own_meaningful_name\",\n",
    "        \"hidden_units\": 128,\n",
    "         ...\n",
    "     },\n",
    "    {\n",
    "        \"name\": \"second_run_or...\",\n",
    "        \"hidden_units\": 128,\n",
    "        \"dropout\": 0.1,\n",
    "        \"learning_rate\": 0.03,\n",
    "        \"epochs\": 150,\n",
    "        \"batch_size\": 32,    \n",
    "    }\n",
    "}\n",
    "\n",
    "for config in configs:\n",
    "    # in python we can in elegant way merge two dicts using \"|\" operator - finally...\n",
    "    # old merging method {**base_config, **config} - ugly :(\n",
    "    training_config = base_config | config \n",
    "    trainer = PyTorchTrainer(training_config[\"model_class\"], preprocessor, training_config)\n",
    "    results = trainer.fit(X_train, y_train, X_test, y_test)\n",
    "```\n",
    "\n",
    "or just manually and incrementally:\n",
    "\n",
    "```python\n",
    "new_config = {\n",
    "    \"name\": \"second_run_or...\",\n",
    "    \"hidden_units\": 128,\n",
    "    \"dropout\": 0.1,\n",
    "    \"learning_rate\": 0.03,\n",
    "    \"epochs\": 150,\n",
    "    \"batch_size\": 32,    \n",
    "}\n",
    "\n",
    "training_config = base_config | config \n",
    "trainer = PyTorchTrainer(training_config[\"model_class\"], preprocessor, training_config)\n",
    "results = trainer.fit(X_train, y_train, X_test, y_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "299c2bb3-145e-4769-8691-b78a8d625c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_config = {\n",
    "    \"model_class\": HousePriceNet,\n",
    "    \"random_seed\": 42,\n",
    "    \"log_interval\": 5,\n",
    "    \"input_features\": X_train.shape[1],\n",
    "    \"num_samples\": X_train.shape[0],\n",
    "    \"target_normalized\": True,\n",
    "    \"k_folds\": 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6d9bb0f-dcc4-4ab1-8d71-05cf4f9558b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_units = [32, 64, 128]\n",
    "dropouts = [0.1, 0.2]\n",
    "learning_rates = [0.01, 0.03]\n",
    "\n",
    "configs = [\n",
    "    {\n",
    "        \"hidden_units\": hidden_unit,\n",
    "        \"dropout\": dropout,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"epochs\": 150,\n",
    "        \"batch_size\": 32,  \n",
    "    }\n",
    "    for hidden_unit in hidden_units\n",
    "    for dropout in dropouts \n",
    "    for learning_rate in learning_rates\n",
    "]\n",
    "\n",
    "configs = [ config | { \"name\": f\"run_{idx}\" } for idx, config in enumerate(configs) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef9a4b2e-0608-44dd-9708-b0c9b1bb158d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ce6ec56-e0cf-41a8-9550-c656620d35e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 1312\n",
      "Input features: 181\n",
      "Starting 5-fold cross-validation for run_0...\n",
      "\n",
      "Training Fold 1/5...\n",
      "  Fold 1 Validation - RMSE: 28541.60, MAE: 21362.13 R^2: 0.887\n",
      "\n",
      "Training Fold 2/5...\n",
      "  Fold 2 Validation - RMSE: 23638.85, MAE: 17084.26 R^2: 0.908\n",
      "\n",
      "Training Fold 3/5...\n",
      "  Fold 3 Validation - RMSE: 42358.26, MAE: 31400.57 R^2: 0.733\n",
      "\n",
      "Training Fold 4/5...\n",
      "  Fold 4 Validation - RMSE: 30861.20, MAE: 22200.07 R^2: 0.833\n",
      "\n",
      "Training Fold 5/5...\n",
      "  Fold 5 Validation - RMSE: 49868.24, MAE: 37974.61 R^2: 0.572\n",
      "\n",
      "Cross-validation complete. Mean R^2: 0.787 (+/- 0.123)\n",
      "\n",
      "Training final model on all training data...\n",
      "\n",
      "Evaluating on test set...\n",
      "==================================================\n",
      "\n",
      "  Mean R^2: 0.787 (+/- 0.123)\n",
      "\n",
      "Cross-Validation Performance:\n",
      "  R^2: 0.867\n",
      "  RMSE: 27570.00\n",
      "  MAE: 19064.68\n",
      "Test Set Performance:\n",
      "==================================================\n",
      "FINAL RESULTS for run_0:\n",
      "\n",
      "==================================================\n",
      "🏃 View run run_0 at: http://localhost:5001/#/experiments/2/runs/6eb9dbfca7c5427f8a782faede39aabf\n",
      "🧪 View experiment at: http://localhost:5001/#/experiments/2\n",
      "Training samples: 1312\n",
      "Input features: 181\n",
      "Starting 5-fold cross-validation for run_1...\n",
      "\n",
      "Training Fold 1/5...\n",
      "  Fold 1 Validation - RMSE: 23204.74, MAE: 15889.26 R^2: 0.925\n",
      "\n",
      "Training Fold 2/5...\n",
      "  Fold 2 Validation - RMSE: 20501.76, MAE: 13737.69 R^2: 0.931\n",
      "\n",
      "Training Fold 3/5...\n",
      "  Fold 3 Validation - RMSE: 23837.36, MAE: 15758.89 R^2: 0.915\n",
      "\n",
      "Training Fold 4/5...\n",
      "  Fold 4 Validation - RMSE: 27068.07, MAE: 18301.03 R^2: 0.872\n",
      "\n",
      "Training Fold 5/5...\n",
      "  Fold 5 Validation - RMSE: 22453.39, MAE: 15286.50 R^2: 0.913\n",
      "\n",
      "Cross-validation complete. Mean R^2: 0.911 (+/- 0.021)\n",
      "\n",
      "Training final model on all training data...\n",
      "\n",
      "Evaluating on test set...\n",
      "==================================================\n",
      "\n",
      "  Mean R^2: 0.911 (+/- 0.021)\n",
      "\n",
      "Cross-Validation Performance:\n",
      "  R^2: 0.884\n",
      "  RMSE: 25748.94\n",
      "  MAE: 17840.78\n",
      "Test Set Performance:\n",
      "==================================================\n",
      "FINAL RESULTS for run_1:\n",
      "\n",
      "==================================================\n",
      "🏃 View run run_1 at: http://localhost:5001/#/experiments/2/runs/547fda2bf53c48b392c4406fffe42909\n",
      "🧪 View experiment at: http://localhost:5001/#/experiments/2\n",
      "Training samples: 1312\n",
      "Input features: 181\n",
      "Starting 5-fold cross-validation for run_2...\n",
      "\n",
      "Training Fold 1/5...\n",
      "  Fold 1 Validation - RMSE: 24910.39, MAE: 16967.65 R^2: 0.914\n",
      "\n",
      "Training Fold 2/5...\n",
      "  Fold 2 Validation - RMSE: 30485.59, MAE: 21151.53 R^2: 0.848\n",
      "\n",
      "Training Fold 3/5...\n",
      "  Fold 3 Validation - RMSE: 29438.34, MAE: 18236.32 R^2: 0.871\n",
      "\n",
      "Training Fold 4/5...\n",
      "  Fold 4 Validation - RMSE: 20429.25, MAE: 13850.56 R^2: 0.927\n",
      "\n",
      "Training Fold 5/5...\n",
      "  Fold 5 Validation - RMSE: 27861.93, MAE: 18656.99 R^2: 0.866\n",
      "\n",
      "Cross-validation complete. Mean R^2: 0.885 (+/- 0.030)\n",
      "\n",
      "Training final model on all training data...\n",
      "\n",
      "Evaluating on test set...\n",
      "==================================================\n",
      "\n",
      "  Mean R^2: 0.885 (+/- 0.030)\n",
      "\n",
      "Cross-Validation Performance:\n",
      "  R^2: 0.881\n",
      "  RMSE: 26038.95\n",
      "  MAE: 18282.00\n",
      "Test Set Performance:\n",
      "==================================================\n",
      "FINAL RESULTS for run_2:\n",
      "\n",
      "==================================================\n",
      "🏃 View run run_2 at: http://localhost:5001/#/experiments/2/runs/0731d0aac5d2417aa865cb59d8e903aa\n",
      "🧪 View experiment at: http://localhost:5001/#/experiments/2\n",
      "Training samples: 1312\n",
      "Input features: 181\n",
      "Starting 5-fold cross-validation for run_3...\n",
      "\n",
      "Training Fold 1/5...\n",
      "  Fold 1 Validation - RMSE: 23211.06, MAE: 15575.27 R^2: 0.925\n",
      "\n",
      "Training Fold 2/5...\n",
      "  Fold 2 Validation - RMSE: 22466.88, MAE: 14391.29 R^2: 0.917\n",
      "\n",
      "Training Fold 3/5...\n",
      "  Fold 3 Validation - RMSE: 27596.56, MAE: 17428.92 R^2: 0.887\n",
      "\n",
      "Training Fold 4/5...\n",
      "  Fold 4 Validation - RMSE: 27684.17, MAE: 18542.60 R^2: 0.866\n",
      "\n",
      "Training Fold 5/5...\n",
      "  Fold 5 Validation - RMSE: 26409.91, MAE: 18811.10 R^2: 0.880\n",
      "\n",
      "Cross-validation complete. Mean R^2: 0.895 (+/- 0.023)\n",
      "\n",
      "Training final model on all training data...\n",
      "\n",
      "Evaluating on test set...\n",
      "==================================================\n",
      "\n",
      "  Mean R^2: 0.895 (+/- 0.023)\n",
      "\n",
      "Cross-Validation Performance:\n",
      "  R^2: 0.727\n",
      "  RMSE: 39516.59\n",
      "  MAE: 30481.20\n",
      "Test Set Performance:\n",
      "==================================================\n",
      "FINAL RESULTS for run_3:\n",
      "\n",
      "==================================================\n",
      "🏃 View run run_3 at: http://localhost:5001/#/experiments/2/runs/fd88f75f4dd843a2af48c0d9100cf2ff\n",
      "🧪 View experiment at: http://localhost:5001/#/experiments/2\n",
      "Training samples: 1312\n",
      "Input features: 181\n",
      "Starting 5-fold cross-validation for run_4...\n",
      "\n",
      "Training Fold 1/5...\n",
      "  Fold 1 Validation - RMSE: 46503.65, MAE: 31889.14 R^2: 0.700\n",
      "\n",
      "Training Fold 2/5...\n",
      "  Fold 2 Validation - RMSE: 34947.25, MAE: 25983.48 R^2: 0.800\n",
      "\n",
      "Training Fold 3/5...\n",
      "  Fold 3 Validation - RMSE: 37425.58, MAE: 24905.88 R^2: 0.791\n",
      "\n",
      "Training Fold 4/5...\n",
      "  Fold 4 Validation - RMSE: 34728.18, MAE: 26734.80 R^2: 0.789\n",
      "\n",
      "Training Fold 5/5...\n",
      "  Fold 5 Validation - RMSE: 39872.82, MAE: 29675.41 R^2: 0.726\n",
      "\n",
      "Cross-validation complete. Mean R^2: 0.761 (+/- 0.040)\n",
      "\n",
      "Training final model on all training data...\n",
      "\n",
      "Evaluating on test set...\n",
      "==================================================\n",
      "\n",
      "  Mean R^2: 0.761 (+/- 0.040)\n",
      "\n",
      "Cross-Validation Performance:\n",
      "  R^2: 0.844\n",
      "  RMSE: 29829.05\n",
      "  MAE: 21366.29\n",
      "Test Set Performance:\n",
      "==================================================\n",
      "FINAL RESULTS for run_4:\n",
      "\n",
      "==================================================\n",
      "🏃 View run run_4 at: http://localhost:5001/#/experiments/2/runs/f9b5eec4cffc40c8b9e4a05484f788d0\n",
      "🧪 View experiment at: http://localhost:5001/#/experiments/2\n",
      "Training samples: 1312\n",
      "Input features: 181\n",
      "Starting 5-fold cross-validation for run_5...\n",
      "\n",
      "Training Fold 1/5...\n",
      "  Fold 1 Validation - RMSE: 25406.72, MAE: 17609.11 R^2: 0.911\n",
      "\n",
      "Training Fold 2/5...\n",
      "  Fold 2 Validation - RMSE: 21885.56, MAE: 16087.03 R^2: 0.921\n",
      "\n",
      "Training Fold 3/5...\n",
      "  Fold 3 Validation - RMSE: 25437.97, MAE: 17595.36 R^2: 0.904\n",
      "\n",
      "Training Fold 4/5...\n",
      "  Fold 4 Validation - RMSE: 25218.13, MAE: 16898.93 R^2: 0.889\n",
      "\n",
      "Training Fold 5/5...\n",
      "  Fold 5 Validation - RMSE: 30294.43, MAE: 22551.30 R^2: 0.842\n",
      "\n",
      "Cross-validation complete. Mean R^2: 0.893 (+/- 0.028)\n",
      "\n",
      "Training final model on all training data...\n",
      "\n",
      "Evaluating on test set...\n",
      "==================================================\n",
      "\n",
      "  Mean R^2: 0.893 (+/- 0.028)\n",
      "\n",
      "Cross-Validation Performance:\n",
      "  R^2: 0.915\n",
      "  RMSE: 22082.41\n",
      "  MAE: 15087.67\n",
      "Test Set Performance:\n",
      "==================================================\n",
      "FINAL RESULTS for run_5:\n",
      "\n",
      "==================================================\n",
      "🏃 View run run_5 at: http://localhost:5001/#/experiments/2/runs/0a2a9ed1e9844c4791bc5a806ee96114\n",
      "🧪 View experiment at: http://localhost:5001/#/experiments/2\n",
      "Training samples: 1312\n",
      "Input features: 181\n",
      "Starting 5-fold cross-validation for run_6...\n",
      "\n",
      "Training Fold 1/5...\n",
      "  Fold 1 Validation - RMSE: 25197.22, MAE: 18157.21 R^2: 0.912\n",
      "\n",
      "Training Fold 2/5...\n",
      "  Fold 2 Validation - RMSE: 46192.38, MAE: 36713.65 R^2: 0.650\n",
      "\n",
      "Training Fold 3/5...\n",
      "  Fold 3 Validation - RMSE: 29012.13, MAE: 20206.89 R^2: 0.875\n",
      "\n",
      "Training Fold 4/5...\n",
      "  Fold 4 Validation - RMSE: 50642.12, MAE: 40608.93 R^2: 0.551\n",
      "\n",
      "Training Fold 5/5...\n",
      "  Fold 5 Validation - RMSE: 27816.94, MAE: 19521.95 R^2: 0.867\n",
      "\n",
      "Cross-validation complete. Mean R^2: 0.771 (+/- 0.143)\n",
      "\n",
      "Training final model on all training data...\n",
      "\n",
      "Evaluating on test set...\n",
      "==================================================\n",
      "\n",
      "  Mean R^2: 0.771 (+/- 0.143)\n",
      "\n",
      "Cross-Validation Performance:\n",
      "  R^2: 0.847\n",
      "  RMSE: 29556.43\n",
      "  MAE: 21374.36\n",
      "Test Set Performance:\n",
      "==================================================\n",
      "FINAL RESULTS for run_6:\n",
      "\n",
      "==================================================\n",
      "🏃 View run run_6 at: http://localhost:5001/#/experiments/2/runs/d8a8445f5e254b8f95f78148bb635dc8\n",
      "🧪 View experiment at: http://localhost:5001/#/experiments/2\n",
      "Training samples: 1312\n",
      "Input features: 181\n",
      "Starting 5-fold cross-validation for run_7...\n",
      "\n",
      "Training Fold 1/5...\n",
      "  Fold 1 Validation - RMSE: 23122.99, MAE: 15612.45 R^2: 0.926\n",
      "\n",
      "Training Fold 2/5...\n",
      "  Fold 2 Validation - RMSE: 21105.89, MAE: 15030.78 R^2: 0.927\n",
      "\n",
      "Training Fold 3/5...\n",
      "  Fold 3 Validation - RMSE: 23881.09, MAE: 15416.12 R^2: 0.915\n",
      "\n",
      "Training Fold 4/5...\n",
      "  Fold 4 Validation - RMSE: 25257.40, MAE: 16524.96 R^2: 0.888\n",
      "\n",
      "Training Fold 5/5...\n",
      "  Fold 5 Validation - RMSE: 23089.97, MAE: 16324.01 R^2: 0.908\n",
      "\n",
      "Cross-validation complete. Mean R^2: 0.913 (+/- 0.014)\n",
      "\n",
      "Training final model on all training data...\n",
      "\n",
      "Evaluating on test set...\n",
      "==================================================\n",
      "\n",
      "  Mean R^2: 0.913 (+/- 0.014)\n",
      "\n",
      "Cross-Validation Performance:\n",
      "  R^2: 0.868\n",
      "  RMSE: 27506.16\n",
      "  MAE: 18721.79\n",
      "Test Set Performance:\n",
      "==================================================\n",
      "FINAL RESULTS for run_7:\n",
      "\n",
      "==================================================\n",
      "🏃 View run run_7 at: http://localhost:5001/#/experiments/2/runs/2dd9bc46bd2b46adabb23753c59383c1\n",
      "🧪 View experiment at: http://localhost:5001/#/experiments/2\n",
      "Training samples: 1312\n",
      "Input features: 181\n",
      "Starting 5-fold cross-validation for run_8...\n",
      "\n",
      "Training Fold 1/5...\n",
      "  Fold 1 Validation - RMSE: 42010.63, MAE: 30217.49 R^2: 0.755\n",
      "\n",
      "Training Fold 2/5...\n",
      "  Fold 2 Validation - RMSE: 84417.69, MAE: 57075.71 R^2: -0.168\n",
      "\n",
      "Training Fold 3/5...\n",
      "  Fold 3 Validation - RMSE: 41014.70, MAE: 31831.68 R^2: 0.749\n",
      "\n",
      "Training Fold 4/5...\n",
      "  Fold 4 Validation - RMSE: 39977.68, MAE: 28540.78 R^2: 0.720\n",
      "\n",
      "Training Fold 5/5...\n",
      "  Fold 5 Validation - RMSE: 41493.07, MAE: 30785.94 R^2: 0.704\n",
      "\n",
      "Cross-validation complete. Mean R^2: 0.552 (+/- 0.361)\n",
      "\n",
      "Training final model on all training data...\n",
      "\n",
      "Evaluating on test set...\n",
      "==================================================\n",
      "\n",
      "  Mean R^2: 0.552 (+/- 0.361)\n",
      "\n",
      "Cross-Validation Performance:\n",
      "  R^2: 0.775\n",
      "  RMSE: 35857.13\n",
      "  MAE: 26227.35\n",
      "Test Set Performance:\n",
      "==================================================\n",
      "FINAL RESULTS for run_8:\n",
      "\n",
      "==================================================\n",
      "🏃 View run run_8 at: http://localhost:5001/#/experiments/2/runs/22fb386be4c6408b927e4f530d58f2b3\n",
      "🧪 View experiment at: http://localhost:5001/#/experiments/2\n",
      "Training samples: 1312\n",
      "Input features: 181\n",
      "Starting 5-fold cross-validation for run_9...\n",
      "\n",
      "Training Fold 1/5...\n",
      "  Fold 1 Validation - RMSE: 25630.45, MAE: 18120.44 R^2: 0.909\n",
      "\n",
      "Training Fold 2/5...\n",
      "  Fold 2 Validation - RMSE: 34664.56, MAE: 25032.36 R^2: 0.803\n",
      "\n",
      "Training Fold 3/5...\n",
      "  Fold 3 Validation - RMSE: 26969.20, MAE: 18059.67 R^2: 0.892\n",
      "\n",
      "Training Fold 4/5...\n",
      "  Fold 4 Validation - RMSE: 38612.98, MAE: 25074.29 R^2: 0.739\n",
      "\n",
      "Training Fold 5/5...\n",
      "  Fold 5 Validation - RMSE: 44909.57, MAE: 36566.69 R^2: 0.653\n",
      "\n",
      "Cross-validation complete. Mean R^2: 0.799 (+/- 0.096)\n",
      "\n",
      "Training final model on all training data...\n",
      "\n",
      "Evaluating on test set...\n",
      "==================================================\n",
      "\n",
      "  Mean R^2: 0.799 (+/- 0.096)\n",
      "\n",
      "Cross-Validation Performance:\n",
      "  R^2: 0.883\n",
      "  RMSE: 25874.64\n",
      "  MAE: 17111.36\n",
      "Test Set Performance:\n",
      "==================================================\n",
      "FINAL RESULTS for run_9:\n",
      "\n",
      "==================================================\n",
      "🏃 View run run_9 at: http://localhost:5001/#/experiments/2/runs/ac009342ded74399a3c248de41710e49\n",
      "🧪 View experiment at: http://localhost:5001/#/experiments/2\n",
      "Training samples: 1312\n",
      "Input features: 181\n",
      "Starting 5-fold cross-validation for run_10...\n",
      "\n",
      "Training Fold 1/5...\n",
      "  Fold 1 Validation - RMSE: 40066.99, MAE: 29200.59 R^2: 0.778\n",
      "\n",
      "Training Fold 2/5...\n",
      "  Fold 2 Validation - RMSE: 135006.75, MAE: 106772.27 R^2: -1.988\n",
      "\n",
      "Training Fold 3/5...\n",
      "  Fold 3 Validation - RMSE: 43999.18, MAE: 31459.58 R^2: 0.712\n",
      "\n",
      "Training Fold 4/5...\n",
      "  Fold 4 Validation - RMSE: 39697.62, MAE: 28396.26 R^2: 0.724\n",
      "\n",
      "Training Fold 5/5...\n",
      "  Fold 5 Validation - RMSE: 51118.05, MAE: 33229.77 R^2: 0.550\n",
      "\n",
      "Cross-validation complete. Mean R^2: 0.155 (+/- 1.074)\n",
      "\n",
      "Training final model on all training data...\n",
      "\n",
      "Evaluating on test set...\n",
      "==================================================\n",
      "\n",
      "  Mean R^2: 0.155 (+/- 1.074)\n",
      "\n",
      "Cross-Validation Performance:\n",
      "  R^2: 0.811\n",
      "  RMSE: 32854.16\n",
      "  MAE: 22098.42\n",
      "Test Set Performance:\n",
      "==================================================\n",
      "FINAL RESULTS for run_10:\n",
      "\n",
      "==================================================\n",
      "🏃 View run run_10 at: http://localhost:5001/#/experiments/2/runs/d29acf4ed589462a85a3eff62f6dc797\n",
      "🧪 View experiment at: http://localhost:5001/#/experiments/2\n",
      "Training samples: 1312\n",
      "Input features: 181\n",
      "Starting 5-fold cross-validation for run_11...\n",
      "\n",
      "Training Fold 1/5...\n",
      "  Fold 1 Validation - RMSE: 28449.06, MAE: 19115.03 R^2: 0.888\n",
      "\n",
      "Training Fold 2/5...\n",
      "  Fold 2 Validation - RMSE: 22000.01, MAE: 16298.88 R^2: 0.921\n",
      "\n",
      "Training Fold 3/5...\n",
      "  Fold 3 Validation - RMSE: 24666.17, MAE: 16167.00 R^2: 0.909\n",
      "\n",
      "Training Fold 4/5...\n",
      "  Fold 4 Validation - RMSE: 24813.99, MAE: 16887.56 R^2: 0.892\n",
      "\n",
      "Training Fold 5/5...\n",
      "  Fold 5 Validation - RMSE: 27601.37, MAE: 20487.65 R^2: 0.869\n",
      "\n",
      "Cross-validation complete. Mean R^2: 0.896 (+/- 0.018)\n",
      "\n",
      "Training final model on all training data...\n",
      "\n",
      "Evaluating on test set...\n",
      "==================================================\n",
      "\n",
      "  Mean R^2: 0.896 (+/- 0.018)\n",
      "\n",
      "Cross-Validation Performance:\n",
      "  R^2: 0.849\n",
      "  RMSE: 29421.00\n",
      "  MAE: 18743.14\n",
      "Test Set Performance:\n",
      "==================================================\n",
      "FINAL RESULTS for run_11:\n",
      "\n",
      "==================================================\n",
      "🏃 View run run_11 at: http://localhost:5001/#/experiments/2/runs/b9d450fbd212451ba738ec31e5aa7c38\n",
      "🧪 View experiment at: http://localhost:5001/#/experiments/2\n"
     ]
    }
   ],
   "source": [
    "for idx, config in enumerate(configs):\n",
    "    # in python we can in elegant way merge two dicts using \"|\" operator - finally...\n",
    "    # old merging method {**base_config, **config} - ugly :(\n",
    "    training_config = base_config | config\n",
    "\n",
    "    trainer = PyTorchTrainer(training_config[\"model_class\"], training_config)\n",
    "    results = trainer.fit(X_train, y_train_log, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae23a2e-aab6-40f4-9811-6b97a0f9a4d1",
   "metadata": {},
   "source": [
    "### Lab assessment\n",
    "\n",
    "Fill the code exercises in this Jupyter notebook, and send it with completed exercises, written comments in Markdown cells (particularly for questions in exercise 2), and screenshots of results in MLflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2de8c9-7aa4-47f5-ace5-b8236825df62",
   "metadata": {},
   "source": [
    "3. Comment on what changes impacted the model performance the most, and what changes disrupted the training process.\n",
    "\n",
    "Best two runs judging by the `final_model_train_mse` metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0381a74a-52de-4968-a804-ac710db3a7d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'hidden_units': 64,\n",
       "  'dropout': 0.2,\n",
       "  'learning_rate': 0.03,\n",
       "  'epochs': 150,\n",
       "  'batch_size': 32,\n",
       "  'name': 'run_7'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[config for config in configs if config[\"name\"]==\"run_7\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37d8297a-35ea-4e21-8f6f-bd1df8622d96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'hidden_units': 64,\n",
       "  'dropout': 0.1,\n",
       "  'learning_rate': 0.03,\n",
       "  'epochs': 150,\n",
       "  'batch_size': 32,\n",
       "  'name': 'run_5'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[config for config in configs if config[\"name\"]==\"run_5\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4c48fd-4fcc-43f6-803f-c4df88cf77f7",
   "metadata": {},
   "source": [
    "Worst two runs judging by the `final_model_train_mse` metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e88890fa-8b03-4bf3-8373-44e94feef2fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'hidden_units': 128,\n",
       "  'dropout': 0.1,\n",
       "  'learning_rate': 0.01,\n",
       "  'epochs': 150,\n",
       "  'batch_size': 32,\n",
       "  'name': 'run_8'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[config for config in configs if config[\"name\"]==\"run_8\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5fbca952-8af7-431c-b0d2-8c967a7b778c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'hidden_units': 64,\n",
       "  'dropout': 0.1,\n",
       "  'learning_rate': 0.01,\n",
       "  'epochs': 150,\n",
       "  'batch_size': 32,\n",
       "  'name': 'run_4'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[config for config in configs if config[\"name\"]==\"run_4\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b9fe63-2b90-44e4-950f-5622706a4c56",
   "metadata": {},
   "source": [
    "Comments:\n",
    "It looks like the higher learning rate(`0.03`) ended up being more optimal. Also, both of the best models had 64 hidden units in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70227c40-ac90-41c8-be6b-099a35cc2891",
   "metadata": {},
   "source": [
    "4. Compare the results of our first scikit-learn configuration with the first PyTorch experiments. Do you see any overfitting in the first PyTorch experiment? Explain what signs of overfitting can indicate this situation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26800b1d-0ddb-48cb-8497-b1d1e744a890",
   "metadata": {},
   "source": [
    "Comments:\n",
    "\n",
    "As seen in the screenshots from MLflow the first PyTorch experiments ended up being middle-of-the-pack. The only difference when compared to one of the best models is number of `hidden_units`. The worse performing model has twice the number of hidden units indicating a possibility of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c908951e-ab6c-479b-a1df-30c3d19a22a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops_lab06",
   "language": "python",
   "name": "mlops_lab06"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
